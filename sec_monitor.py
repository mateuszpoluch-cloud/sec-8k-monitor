import requests
import json
from datetime import datetime, timedelta
import os
from typing import List, Dict

# Konfiguracja
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL', '')
USER_AGENT = "SEC-Monitor/1.0 (your-email@example.com)"  # ZMIEÅƒ NA SWÃ“J EMAIL

# Lista spÃ³Å‚ek z ekosystemu AI/pÃ³Å‚przewodnikÃ³w
COMPANIES = {
    # Producenci chipÃ³w AI
    'NVDA': {'name': 'NVIDIA', 'cik': '0001045810', 'desc': 'Producent chipÃ³w GPU dla AI i datacenter'},
    'AMD': {'name': 'AMD', 'cik': '0000002488', 'desc': 'Procesory, GPU i chipy dla datacenter'},
    'INTC': {'name': 'Intel', 'cik': '0000050863', 'desc': 'Procesory CPU i komponenty pÃ³Å‚przewodnikowe'},
    'AVGO': {'name': 'Broadcom', 'cik': '0001730168', 'desc': 'Chipy komunikacyjne i pÃ³Å‚przewodniki'},
    'QCOM': {'name': 'Qualcomm', 'cik': '0000804328', 'desc': 'Chipy mobilne i technologie bezprzewodowe'},
    'MRVL': {'name': 'Marvell', 'cik': '0001058057', 'desc': 'PÃ³Å‚przewodniki dla datacenter i 5G'},
    
    # PÃ³Å‚przewodniki & sprzÄ™t
    'ASML': {'name': 'ASML', 'cik': '0000937966', 'desc': 'Maszyny litograficzne do produkcji chipÃ³w'},
    'AMAT': {'name': 'Applied Materials', 'cik': '0000006951', 'desc': 'SprzÄ™t do produkcji pÃ³Å‚przewodnikÃ³w'},
    'LRCX': {'name': 'Lam Research', 'cik': '0000707549', 'desc': 'Technologie trawienia i depozycji chipÃ³w'},
    'KLAC': {'name': 'KLA Corporation', 'cik': '0000319201', 'desc': 'Kontrola jakoÅ›ci w produkcji chipÃ³w'},
    'TSM': {'name': 'TSMC', 'cik': '0001046179', 'desc': 'NajwiÄ™ksza fabryka chipÃ³w (foundry)'},
    
    # PamiÄ™ci & storage
    'MU': {'name': 'Micron', 'cik': '0000723125', 'desc': 'PamiÄ™ci RAM i storage dla AI'},
    'WDC': {'name': 'Western Digital', 'cik': '0000106040', 'desc': 'Dyski twarde i pamiÄ™ci flash'},
    'STX': {'name': 'Seagate', 'cik': '0001137789', 'desc': 'Dyski twarde i rozwiÄ…zania storage'},
    
    # MateriaÅ‚y & komponenty
    'ENTG': {'name': 'Entegris', 'cik': '0001101302', 'desc': 'MateriaÅ‚y chemiczne do produkcji chipÃ³w'},
    'MPWR': {'name': 'Monolithic Power', 'cik': '0001280452', 'desc': 'UkÅ‚ady zarzÄ…dzania energiÄ…'},
    
    # Infrastruktura AI
    'ORCL': {'name': 'Oracle', 'cik': '0001341439', 'desc': 'Bazy danych i cloud computing'},
    'SNOW': {'name': 'Snowflake', 'cik': '0001640147', 'desc': 'Platforma analityki danych w chmurze'},
    'MDB': {'name': 'MongoDB', 'cik': '0001441404', 'desc': 'Bazy danych NoSQL'},
    'PLTR': {'name': 'Palantir', 'cik': '0001321655', 'desc': 'Analityka AI i big data'},
    
    # ARM & Design
    'ARM': {'name': 'Arm Holdings', 'cik': '0001996864', 'desc': 'Architektura procesorÃ³w ARM'},
}

# PowiÄ…zania miÄ™dzy spÃ³Å‚kami z wyjaÅ›nieniami
RELATIONSHIPS = {
    'ASML': {
        'TSM': 'produkuje maszyny litograficzne dla TSMC',
        'INTC': 'dostarcza sprzÄ™t produkcyjny',
        'AMAT': 'konkurent w sprzÄ™cie pÃ³Å‚przewodnikowym',
        'LRCX': 'konkurent w sprzÄ™cie pÃ³Å‚przewodnikowym'
    },
    'TSM': {
        'NVDA': 'produkuje chipy GPU dla NVIDIA',
        'AMD': 'produkuje procesory i GPU dla AMD',
        'QCOM': 'produkuje chipy mobilne',
        'MRVL': 'produkuje chipy dla Marvell'
    },
    'NVDA': {
        'TSM': 'TSMC produkuje ich chipy',
        'MU': 'Micron dostarcza pamiÄ™ci do kart graficznych',
        'MPWR': 'ukÅ‚ady zasilajÄ…ce do GPU',
        'SNOW': 'klient uÅ¼ywajÄ…cy GPU do AI',
        'ORCL': 'klient kupujÄ…cy serwery z GPU'
    },
    'AMD': {
        'TSM': 'TSMC produkuje ich procesory i GPU',
        'MU': 'Micron dostarcza pamiÄ™ci',
        'MPWR': 'ukÅ‚ady zasilajÄ…ce do procesorÃ³w'
    },
    'INTC': {
        'AMAT': 'kupuje sprzÄ™t do produkcji chipÃ³w',
        'LRCX': 'kupuje sprzÄ™t litograficzny',
        'ASML': 'kupuje maszyny EUV'
    },
    'MU': {
        'NVDA': 'dostarcza pamiÄ™Ä‡ dla kart graficznych',
        'AMD': 'dostarcza pamiÄ™Ä‡ dla GPU/CPU',
        'INTC': 'konkurent w pamiÄ™ciach'
    },
    'AMAT': {
        'TSM': 'dostarcza sprzÄ™t produkcyjny',
        'INTC': 'dostarcza narzÄ™dzia do fabryk',
        'ASML': 'partner w ekosystemie produkcji'
    },
    'LRCX': {
        'TSM': 'sprzÄ™t do trawienia i depozycji',
        'INTC': 'sprzÄ™t produkcyjny',
        'ASML': 'uzupeÅ‚niajÄ…cy sprzÄ™t litograficzny'
    },
    'ENTG': {
        'TSM': 'dostarcza chemikalia produkcyjne',
        'INTC': 'materiaÅ‚y do produkcji chipÃ³w',
        'AMAT': 'materiaÅ‚y do procesÃ³w produkcyjnych'
    },
    'MPWR': {
        'NVDA': 'zarzÄ…dzanie energiÄ… dla GPU',
        'AMD': 'ukÅ‚ady zasilajÄ…ce procesory/GPU'
    },
    'AVGO': {
        'AAPL': 'dostarcza komponenty RF',
        'TSM': 'produkujÄ… ich chipy'
    },
    'QCOM': {
        'TSM': 'TSMC produkuje ich chipy mobilne',
        'AAPL': 'konkurent w chipach mobilnych'
    },
    'MRVL': {
        'TSM': 'produkujÄ… ich chipy',
        'NVDA': 'konkurent w chipach datacenter'
    },
    'KLAC': {
        'TSM': 'sprzÄ™t kontroli jakoÅ›ci',
        'INTC': 'narzÄ™dzia inspekcyjne',
        'ASML': 'komplementarny sprzÄ™t'
    },
    'WDC': {
        'NVDA': 'storage dla systemÃ³w AI',
        'ORCL': 'storage dla datacenter'
    },
    'STX': {
        'NVDA': 'storage dla AI/datacenter',
        'ORCL': 'storage dla baz danych'
    },
    'ORCL': {
        'NVDA': 'kupuje GPU do cloud',
        'INTC': 'kupuje procesory serwerowe'
    },
    'SNOW': {
        'NVDA': 'uÅ¼ywa GPU do analityki AI',
        'ORCL': 'konkurent w cloud data'
    },
    'MDB': {
        'NVDA': 'uÅ¼ywa GPU dla AI/ML',
        'ORCL': 'konkurent w bazach danych'
    },
    'PLTR': {
        'NVDA': 'uÅ¼ywa GPU do AI analytics',
        'ORCL': 'partner w rozwiÄ…zaniach enterprise'
    },
    'ARM': {
        'NVDA': 'prÃ³ba przejÄ™cia (zablokowana)',
        'AAPL': 'licencja na architekturÄ™ ARM',
        'QCOM': 'licencja ARM dla chipÃ³w mobilnych'
    }
}

# Kategorie 8-K ktÃ³re nas interesujÄ…
IMPORTANT_ITEMS = {
    '1.01': 'PrzejÄ™cia/Fuzje/Akwizycje',
    '1.02': 'Zakup/SprzedaÅ¼ aktywÃ³w',
    '8.01': 'Inne istotne wydarzenia',
    '2.02': 'Wyniki finansowe'
}

# SÅ‚owa kluczowe wskazujÄ…ce na waÅ¼ne wydarzenia
KEYWORDS = [
    'acquisition', 'merger', 'partnership', 'agreement', 'contract',
    'collaboration', 'joint venture', 'strategic', 'ai', 'artificial intelligence',
    'chip', 'semiconductor', 'revenue', 'earnings', 'guidance'
]

def load_processed_filings():
    """Wczytaj listÄ™ przetworzonych raportÃ³w z pliku"""
    try:
        with open('processed_filings.json', 'r') as f:
            data = json.load(f)
            return set(data.get('filings', []))
    except FileNotFoundError:
        return set()

def save_processed_filings(processed):
    """Zapisz listÄ™ przetworzonych raportÃ³w do pliku"""
    with open('processed_filings.json', 'w') as f:
        json.dump({'filings': list(processed)}, f)

def get_recent_filings(cik: str, ticker: str) -> List[Dict]:
    """Pobiera ostatnie zgÅ‚oszenia 8-K dla danej spÃ³Å‚ki"""
    url = f"https://data.sec.gov/submissions/CIK{cik.zfill(10)}.json"
    headers = {'User-Agent': USER_AGENT}
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        recent = data.get('filings', {}).get('recent', {})
        filings = []
        
        for i in range(len(recent.get('form', []))):
            form = recent['form'][i]
            if form == '8-K':
                filing = {
                    'accessionNumber': recent['accessionNumber'][i],
                    'filingDate': recent['filingDate'][i],
                    'acceptanceDateTime': recent.get('acceptanceDateTime', [None] * len(recent['form']))[i],
                    'primaryDocument': recent['primaryDocument'][i],
                    'ticker': ticker,
                    'company': COMPANIES[ticker]['name']
                }
                filings.append(filing)
        
        return filings[:5]
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d pobierania danych dla {ticker}: {e}")
        return []

def translate_to_polish_full(text: str) -> str:
    """PeÅ‚niejsze tÅ‚umaczenie tekstu finansowego na polski"""
    import re
    
    # Mapowanie terminÃ³w - najpierw dÅ‚ugie frazy, potem pojedyncze sÅ‚owa
    translations = {
        # DÅ‚ugie frazy
        'FINANCIAL RESULTS': 'WYNIKI FINANSOWE',
        'financial results': 'wyniki finansowe',
        'Investor Relations': 'Relacje Inwestorskie',
        'Media Contact': 'Kontakt dla mediÃ³w',
        'year-over-year': 'rok do roku',
        'compared to': 'w porÃ³wnaniu do',
        'cash flow from operations': 'przepÅ‚ywy pieniÄ™Å¼ne z operacji',
        'free cash flow': 'wolne przepÅ‚ywy pieniÄ™Å¼ne',
        'returned to shareholders': 'zwrÃ³cono akcjonariuszom',
        'diluted EPS': 'rozwodniony zysk na akcjÄ™',
        'per share': 'na akcjÄ™',
        'gross margin': 'marÅ¼a brutto',
        'net income': 'zysk netto',
        'operating income': 'zysk operacyjny',
        'fiscal year': 'rok fiskalny',
        'fiscal quarter': 'kwartaÅ‚ fiskalny',
        'announced that': 'ogÅ‚osiÅ‚, Å¼e',
        'reports that': 'raportuje, Å¼e',
        'at record levels': 'na rekordowych poziomach',
        
        # Pojedyncze sÅ‚owa
        'TECHNOLOGY': 'TECHNOLOGIA',
        'Technology': 'Technologia',
        'REPORTS': 'RAPORTUJE',
        'reports': 'raportuje',
        'FISCAL': 'FISKALNY',
        'Fiscal': 'Fiskalny',
        'Quarter': 'KwartaÅ‚',
        'quarter': 'kwartaÅ‚',
        'Highlights': 'NajwaÅ¼niejsze',
        'highlights': 'najwaÅ¼niejsze',
        'Revenue': 'Przychody',
        'revenue': 'przychody',
        'revenues': 'przychody',
        'GAAP': 'GAAP',
        'non-GAAP': 'non-GAAP',
        'earnings': 'zyski',
        'income': 'dochÃ³d',
        'margin': 'marÅ¼a',
        'billion': 'miliardÃ³w',
        'million': 'milionÃ³w',
        'approximately': 'okoÅ‚o',
        'quarterly': 'kwartalnie',
        'dividends': 'dywidendy',
        'repurchase': 'wykup',
        'shares': 'akcji',
        'ordinary': 'zwykÅ‚ych',
        'shareholders': 'akcjonariuszy',
        'stockholders': 'akcjonariuszy',
        'through': 'poprzez',
        'announced': 'ogÅ‚osiÅ‚',
        'reported': 'raportowaÅ‚',
        'increased': 'wzrosÅ‚y',
        'decreased': 'spadÅ‚y',
        'growth': 'wzrost',
        'decline': 'spadek',
        'partnership': 'partnerstwo',
        'agreement': 'umowa',
        'acquisition': 'przejÄ™cie',
        'merger': 'fuzja',
        'operations': 'operacji',
        'returned': 'zwrÃ³cono',
        'Returned': 'ZwrÃ³cono',
        'Cash': 'PrzepÅ‚ywy',
        'flow': 'pieniÄ™Å¼ne',
    }
    
    result = text
    
    # Sortuj od najdÅ‚uÅ¼szych do najkrÃ³tszych
    sorted_terms = sorted(translations.items(), key=lambda x: len(x[0]), reverse=True)
    
    for eng, pl in sorted_terms:
        if ' ' in eng:
            # Dla fraz - zamieÅ„ dokÅ‚adnie
            result = result.replace(eng, pl)
        else:
            # Dla pojedynczych sÅ‚Ã³w - uÅ¼yj word boundary
            pattern = r'\b' + re.escape(eng) + r'\b'
            result = re.sub(pattern, pl, result)
    
    return result

def extract_key_numbers(text: str) -> str:
    """WyciÄ…ga najwaÅ¼niejsze liczby i dane z dokumentu"""
    import re
    
    summary = []
    
    # Przychody (revenue)
    revenue_patterns = [
        r'(?:revenue|revenues|przychody).*?\$?\s*(\d+[\.,]\d+)\s*(?:billion|miliardÃ³w|mld)',
        r'\$\s*(\d+[\.,]\d+)\s*(?:billion|miliardÃ³w|mld).*?(?:revenue|przychody)',
    ]
    for pattern in revenue_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            amount = match.group(1).replace(',', '.')
            summary.append(f"ğŸ’° Przychody: ${amount} mld")
            break
    
    # Zyski (earnings/income)
    earnings_patterns = [
        r'(?:net income|zysk netto|earnings|zyski).*?\$?\s*(\d+[\.,]?\d*)\s*(?:million|billion|milionÃ³w|miliardÃ³w|mln|mld)',
        r'\$\s*(\d+[\.,]?\d*)\s*(?:million|billion|milionÃ³w|miliardÃ³w|mln|mld).*?(?:net income|zysk|earnings)',
    ]
    for pattern in earnings_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            amount = match.group(1).replace(',', '.')
            unit = 'mld' if 'billion' in match.group(0).lower() or 'miliardÃ³w' in match.group(0).lower() else 'mln'
            summary.append(f"ğŸ“Š Zysk netto: ${amount} {unit}")
            break
    
    # MarÅ¼a (margin)
    margin_pattern = r'(?:gross margin|marÅ¼a brutto).*?(\d+[\.,]\d+)%'
    match = re.search(margin_pattern, text, re.IGNORECASE)
    if match:
        margin = match.group(1).replace(',', '.')
        summary.append(f"ğŸ“ˆ MarÅ¼a brutto: {margin}%")
    
    # EPS (earnings per share)
    eps_pattern = r'(?:EPS|zysk na akcjÄ™|per share).*?\$?\s*(\d+[\.,]\d+)'
    match = re.search(eps_pattern, text, re.IGNORECASE)
    if match:
        eps = match.group(1).replace(',', '.')
        summary.append(f"ğŸ’µ EPS: ${eps}")
    
    # Wzrost rok do roku (year-over-year growth)
    growth_patterns = [
        r'(?:wzrost|growth|increased).*?(\d+)%',
        r'(\d+)%.*?(?:wzrost|growth|rok do roku)',
    ]
    for pattern in growth_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            growth = match.group(1)
            summary.append(f"ğŸ“Š Wzrost r/r: +{growth}%")
            break
    
    # PrzepÅ‚ywy pieniÄ™Å¼ne (cash flow)
    cashflow_patterns = [
        r'(?:free cash flow|wolne przepÅ‚ywy).*?\$?\s*(\d+)\s*(?:million|milionÃ³w|mln)',
        r'(?:cash flow).*?\$?\s*(\d+)\s*(?:million|milionÃ³w|mln)',
    ]
    for pattern in cashflow_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            cf = match.group(1)
            summary.append(f"ğŸ’¸ Free Cash Flow: ${cf} mln")
            break
    
    # Dywidendy
    dividend_pattern = r'(?:dividend|dywidendy).*?\$?\s*(\d+[\.,]\d+)'
    match = re.search(dividend_pattern, text, re.IGNORECASE)
    if match:
        div = match.group(1).replace(',', '.')
        summary.append(f"ğŸ’ Dywidenda: ${div}")
    
    if summary:
        return "\n".join(summary)
    else:
        return "Brak kluczowych danych liczbowych w fragmencie"
    """WyciÄ…ga fragment dokumentu z najwaÅ¼niejszej sekcji Item"""
    import re
    import html
    
    # ZnajdÅº najwaÅ¼niejszÄ… sekcjÄ™ Item
    priority_items = ['1.01', '1.02', '8.01', '2.02']
    
    for item in priority_items:
        if any(item in detected for detected in detected_items):
            # Szukaj sekcji Item w dokumencie
            pattern = rf'Item\s+{re.escape(item)}[^\n]*\n(.*?)(?=Item\s+\d|\Z)'
            match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
            
            if match:
                excerpt = match.group(1).strip()
                
                # WyczyÅ›Ä‡ z HTML tagÃ³w
                excerpt = re.sub(r'<[^>]+>', '', excerpt)
                
                # Dekoduj HTML entities (&#58; â†’ :, &#64; â†’ @, etc.)
                excerpt = html.unescape(excerpt)
                
                # UsuÅ„ nagÅ‚Ã³wki dokumentu (EX-99.1, numery, itp.)
                excerpt = re.sub(r'^EX-\d+\.\d+.*?\.htm\s*', '', excerpt, flags=re.IGNORECASE)
                excerpt = re.sub(r'^EX-\d+\.\d+\s*', '', excerpt)
                excerpt = re.sub(r'^Document.*?(?=\w{3,})', '', excerpt, flags=re.IGNORECASE | re.DOTALL)
                
                # UsuÅ„ sekcjÄ™ kontaktowÄ…
                excerpt = re.sub(r'Investor Relations Contact:.*?(?=\w{5,}\s+\w{5,})', '', excerpt, flags=re.IGNORECASE | re.DOTALL)
                excerpt = re.sub(r'Media Contact:.*?(?=\w{5,}\s+\w{5,})', '', excerpt, flags=re.IGNORECASE | re.DOTALL)
                excerpt = re.sub(r'Contact:.*?@\S+', '', excerpt, flags=re.IGNORECASE)
                
                # UsuÅ„ numery telefonÃ³w i emaile
                excerpt = re.sub(r'\(\d{3}\)\s*\d{3}-\d{4}', '', excerpt)
                excerpt = re.sub(r'\b[\w\.-]+@[\w\.-]+\.\w+\b', '', excerpt)
                
                # WyczyÅ›Ä‡ dziwne znaki
                excerpt = excerpt.replace('&nbsp;', ' ')
                excerpt = excerpt.replace('&#160;', ' ')
                
                # UsuÅ„ znaki formatowania (bullet points, etc.)
                excerpt = re.sub(r'[â€¢â—¦â–ªâ–¡â– â–ºâ–¶]', '', excerpt)
                
                # Normalizuj biaÅ‚e znaki
                excerpt = re.sub(r'\s+', ' ', excerpt)
                excerpt = excerpt.strip()
                
                # WeÅº od pierwszego sensownego sÅ‚owa
                # PomiÅ„ pozostaÅ‚oÅ›ci nagÅ‚Ã³wkÃ³w
                words = excerpt.split()
                start_idx = 0
                for i, word in enumerate(words):
                    if len(word) > 4 and any(c.isalpha() for c in word):

def analyze_8k_content(accession_number: str, ticker: str) -> Dict:
    """Analizuje treÅ›Ä‡ raportu 8-K"""
    acc_no_dashes = accession_number.replace('-', '')
    cik = COMPANIES[ticker]['cik'].lstrip('0') or '0'
    filing_url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{acc_no_dashes}/{accession_number}.txt"
    headers = {'User-Agent': USER_AGENT}
    
    try:
        response = requests.get(filing_url, headers=headers, timeout=15)
        response.raise_for_status()
        content = response.text
        content_lower = content.lower()
        
        detected_items = []
        for item_num, item_desc in IMPORTANT_ITEMS.items():
            if f"item {item_num}" in content_lower:
                detected_items.append(f"Item {item_num} - {item_desc}")
        
        found_keywords = [kw for kw in KEYWORDS if kw in content_lower]
        importance_score = len(detected_items) * 2 + len(found_keywords)
        
        # WyciÄ…gnij fragment dokumentu
        document_excerpt = extract_document_excerpt(content, detected_items)
        
        return {
            'items': detected_items,
            'keywords': found_keywords[:5],
            'importance': importance_score,
            'document_excerpt': document_excerpt,
            'url': f"https://www.sec.gov/cgi-bin/viewer?action=view&cik={cik}&accession_number={accession_number}"
        }
        
    except Exception as e:
        print(f"âš ï¸ Nie moÅ¼na przeanalizowaÄ‡ treÅ›ci {accession_number}: {e}")
        return {
            'items': [], 
            'keywords': [], 
            'importance': 0, 
            'document_excerpt': 'BÅ‚Ä…d pobierania dokumentu',
            'url': filing_url
        }

def analyze_sentiment(analysis: Dict, ticker: str) -> Dict:
    """Analizuje sentyment raportu 8-K"""
    keywords = analysis.get('keywords', [])
    items = analysis.get('items', [])
    
    # Pozytywne sÅ‚owa kluczowe
    bullish_keywords = ['partnership', 'collaboration', 'strategic', 'agreement', 'contract', 
                        'revenue', 'earnings', 'growth', 'expansion', 'joint venture']
    # Negatywne sÅ‚owa kluczowe
    bearish_keywords = ['loss', 'decline', 'lawsuit', 'investigation', 'bankruptcy', 
                        'restructuring', 'termination', 'failure']
    
    bullish_score = sum(1 for kw in keywords if kw in bullish_keywords)
    bearish_score = sum(1 for kw in keywords if kw in bearish_keywords)
    
    # OkreÅ›l sentyment
    if bullish_score > bearish_score:
        sentiment = "ğŸ“ˆ BULLISH"
        color = 5763719  # Zielony
        interpretation = "Pozytywne wiadomoÅ›ci mogÄ… wspieraÄ‡ wzrost ceny. "
        
        if 'partnership' in keywords or 'collaboration' in keywords:
            interpretation += "Nowe partnerstwo moÅ¼e otworzyÄ‡ dodatkowe ÅºrÃ³dÅ‚a przychodÃ³w."
        elif 'acquisition' in keywords or 'merger' in keywords:
            interpretation += "PrzejÄ™cie/fuzja moÅ¼e zwiÄ™kszyÄ‡ wartoÅ›Ä‡ rynkowÄ… spÃ³Å‚ki."
        elif 'revenue' in keywords or 'earnings' in keywords:
            interpretation += "Dobre wyniki finansowe mogÄ… przyciÄ…gnÄ…Ä‡ inwestorÃ³w."
        else:
            interpretation += "Rynek moÅ¼e zareagowaÄ‡ pozytywnie na te wiadomoÅ›ci."
            
    elif bearish_score > bullish_score:
        sentiment = "ğŸ“‰ BEARISH"
        color = 15158332  # Czerwony
        interpretation = "Negatywne wiadomoÅ›ci mogÄ… wywrzeÄ‡ presjÄ™ na cenÄ™ akcji. "
        interpretation += "Zaleca siÄ™ ostroÅ¼noÅ›Ä‡ i monitorowanie sytuacji."
        
    else:
        sentiment = "â¡ï¸ NEUTRALNY"
        color = 15844367  # Å»Ã³Å‚ty
        interpretation = "WiadomoÅ›ci majÄ… mieszany charakter. "
        interpretation += "WpÅ‚yw na cenÄ™ zaleÅ¼eÄ‡ bÄ™dzie od reakcji rynku i dodatkowych szczegÃ³Å‚Ã³w."
    
    return {
        'sentiment': sentiment,
        'color': color,
        'interpretation': interpretation
    }
    """Analizuje sentyment raportu 8-K"""
    keywords = analysis.get('keywords', [])
    items = analysis.get('items', [])
    
    # Pozytywne sÅ‚owa kluczowe
    bullish_keywords = ['partnership', 'collaboration', 'strategic', 'agreement', 'contract', 
                        'revenue', 'earnings', 'growth', 'expansion', 'joint venture']
    # Negatywne sÅ‚owa kluczowe
    bearish_keywords = ['loss', 'decline', 'lawsuit', 'investigation', 'bankruptcy', 
                        'restructuring', 'termination', 'failure']
    
    bullish_score = sum(1 for kw in keywords if kw in bullish_keywords)
    bearish_score = sum(1 for kw in keywords if kw in bearish_keywords)
    
    # OkreÅ›l sentyment
    if bullish_score > bearish_score:
        sentiment = "ğŸ“ˆ BULLISH"
        color = 5763719  # Zielony
        interpretation = "Pozytywne wiadomoÅ›ci mogÄ… wspieraÄ‡ wzrost ceny. "
        
        if 'partnership' in keywords or 'collaboration' in keywords:
            interpretation += "Nowe partnerstwo moÅ¼e otworzyÄ‡ dodatkowe ÅºrÃ³dÅ‚a przychodÃ³w."
        elif 'acquisition' in keywords or 'merger' in keywords:
            interpretation += "PrzejÄ™cie/fuzja moÅ¼e zwiÄ™kszyÄ‡ wartoÅ›Ä‡ rynkowÄ… spÃ³Å‚ki."
        elif 'revenue' in keywords or 'earnings' in keywords:
            interpretation += "Dobre wyniki finansowe mogÄ… przyciÄ…gnÄ…Ä‡ inwestorÃ³w."
        else:
            interpretation += "Rynek moÅ¼e zareagowaÄ‡ pozytywnie na te wiadomoÅ›ci."
            
    elif bearish_score > bullish_score:
        sentiment = "ğŸ“‰ BEARISH"
        color = 15158332  # Czerwony
        interpretation = "Negatywne wiadomoÅ›ci mogÄ… wywrzeÄ‡ presjÄ™ na cenÄ™ akcji. "
        interpretation += "Zaleca siÄ™ ostroÅ¼noÅ›Ä‡ i monitorowanie sytuacji."
        
    else:
        sentiment = "â¡ï¸ NEUTRALNY"
        color = 15844367  # Å»Ã³Å‚ty
        interpretation = "WiadomoÅ›ci majÄ… mieszany charakter. "
        interpretation += "WpÅ‚yw na cenÄ™ zaleÅ¼eÄ‡ bÄ™dzie od reakcji rynku i dodatkowych szczegÃ³Å‚Ã³w."
    
    return {
        'sentiment': sentiment,
        'color': color,
        'interpretation': interpretation
    }

def send_discord_alert(filing: Dict, analysis: Dict):
    """WysyÅ‚a alert na Discord"""
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ Brak DISCORD_WEBHOOK_URL - pomijam wysyÅ‚anie alertu")
        return
    
    ticker = filing['ticker']
    company = filing['company']
    company_desc = COMPANIES[ticker]['desc']
    date = filing['filingDate']
    
    # Analiza sentymentu
    sentiment_data = analyze_sentiment(analysis, ticker)
    
    # Link do TradingView
    tradingview_link = f"https://www.tradingview.com/chart/?symbol={ticker}"
    
    if analysis['importance'] >= 5:
        priority = "ğŸ”´ BARDZO WAÅ»NE"
    elif analysis['importance'] >= 3:
        priority = "ğŸŸ¡ WAÅ»NE"
    else:
        priority = "ğŸŸ¢ INFORMACYJNE"
    
    # PowiÄ…zane spÃ³Å‚ki z wyjaÅ›nieniami i linkami
    related_companies = RELATIONSHIPS.get(ticker, {})
    if related_companies:
        related_list = []
        count = 0
        for related_ticker, reason in related_companies.items():
            if count >= 4:  # Maksymalnie 4
                break
            tv_link = f"https://www.tradingview.com/chart/?symbol={related_ticker}"
            related_list.append(f"â€¢ [{related_ticker}]({tv_link}) - {reason}")
            count += 1
        related_text = "\n".join(related_list)
    else:
        related_text = "Brak bezpoÅ›rednich powiÄ…zaÅ„ w monitorowanych spÃ³Å‚kach"
    
    items_text = "\n".join([f"â€¢ {item}" for item in analysis['items']]) if analysis['items'] else "Brak wykrytych Items"
    keywords_text = ", ".join(analysis['keywords']) if analysis['keywords'] else "Brak"
    
    embed = {
        "title": f"{priority} - Nowy raport 8-K",
        "description": f"**{company} ({ticker})**\n*{company_desc}*\n\n{sentiment_data['sentiment']}\n*{sentiment_data['interpretation']}*",
        "color": sentiment_data['color'],
        "fields": [
            {"name": "ğŸ“… Data zgÅ‚oszenia", "value": date, "inline": True},
            {"name": "ğŸ“Š Ocena waÅ¼noÅ›ci", "value": f"{analysis['importance']}/10", "inline": True},
            {"name": "ğŸ“‹ Wykryte kategorie", "value": items_text, "inline": False},
            {"name": "ğŸ” Kluczowe sÅ‚owa", "value": keywords_text, "inline": False},
            {"name": "ğŸ”— Potencjalny wpÅ‚yw na", "value": related_text, "inline": False},
            {"name": "ğŸ“ˆ Wykres", "value": f"[OtwÃ³rz na TradingView]({tradingview_link})", "inline": True},
            {"name": "ğŸ“„ Dokument SEC", "value": f"[OtwÃ³rz raport]({analysis['url']})", "inline": True},
            {"name": "ğŸ“„ FRAGMENT DOKUMENTU (tÅ‚umaczenie)", "value": f"```{analysis['document_excerpt']}```", "inline": False}
        ],
        "footer": {"text": f"SEC EDGAR Monitor â€¢ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"}
    }
    
    payload = {"embeds": [embed]}
    
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=10)
        response.raise_for_status()
        print(f"âœ… Alert wysÅ‚any: {ticker} - {date}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d wysyÅ‚ania alertu Discord: {e}")

def check_new_filings():
    """Sprawdza nowe zgÅ‚oszenia dla wszystkich spÃ³Å‚ek"""
    print(f"\nğŸ” Sprawdzam nowe raporty 8-K... [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]")
    
    processed_filings = load_processed_filings()
    new_filings_count = 0
    
    for ticker, info in COMPANIES.items():
        filings = get_recent_filings(info['cik'], ticker)
        
        for filing in filings:
            filing_id = f"{ticker}_{filing['accessionNumber']}"
            
            if filing_id in processed_filings:
                continue
            
            filing_date = datetime.strptime(filing['filingDate'], '%Y-%m-%d')
            if datetime.now() - filing_date > timedelta(hours=48):
                processed_filings.add(filing_id)
                continue
            
            print(f"ğŸ“„ Nowy raport: {ticker} - {filing['filingDate']}")
            
            analysis = analyze_8k_content(filing['accessionNumber'], ticker)
            
            if analysis['items']:
                send_discord_alert(filing, analysis)
                new_filings_count += 1
            
            processed_filings.add(filing_id)
    
    save_processed_filings(processed_filings)
    
    if new_filings_count == 0:
        print("âœ“ Brak nowych raportÃ³w")
    else:
        print(f"âœ“ WysÅ‚ano {new_filings_count} alertÃ³w")

def main():
    """GÅ‚Ã³wna funkcja"""
    print("=" * 60)
    print("ğŸš€ SEC 8-K Monitor - GitHub Actions")
    print("=" * 60)
    print(f"ğŸ“Š Monitorowane spÃ³Å‚ki: {len(COMPANIES)}")
    print(f"ğŸ“‹ Kategorie: {', '.join(IMPORTANT_ITEMS.keys())}")
    print("=" * 60)
    
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ UWAGA: Ustaw DISCORD_WEBHOOK_URL w GitHub Secrets!")
        return
    
    check_new_filings()
    print("\nâœ… ZakoÅ„czono sprawdzanie")

if __name__ == "__main__":
    main(), word):
                        start_idx = i
                        break
                excerpt = ' '.join(words[start_idx:])
                
                # WeÅº pierwsze 1000 znakÃ³w (okoÅ‚o 4-5 zdaÅ„)
                if len(excerpt) > 1000:
                    end = excerpt[:1000].rfind('.')
                    if end > 400:
                        excerpt = excerpt[:end+1]
                    else:
                        excerpt = excerpt[:1000] + '...'
                
                # PrzetÅ‚umacz na polski
                excerpt_pl = translate_to_polish_full(excerpt)
                
                # WyciÄ…gnij kluczowe liczby
                key_numbers = extract_key_numbers(excerpt_pl)
                
                return {
                    'excerpt': excerpt_pl,
                    'key_numbers': key_numbers
                }
    
    return {'excerpt': "Nie udaÅ‚o siÄ™ wyodrÄ™bniÄ‡ fragmentu dokumentu. SprawdÅº peÅ‚ny dokument SEC.", 'key_numbers': "N/A"}

def analyze_8k_content(accession_number: str, ticker: str) -> Dict:
    """Analizuje treÅ›Ä‡ raportu 8-K"""
    acc_no_dashes = accession_number.replace('-', '')
    cik = COMPANIES[ticker]['cik'].lstrip('0') or '0'
    filing_url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{acc_no_dashes}/{accession_number}.txt"
    headers = {'User-Agent': USER_AGENT}
    
    try:
        response = requests.get(filing_url, headers=headers, timeout=15)
        response.raise_for_status()
        content = response.text
        content_lower = content.lower()
        
        detected_items = []
        for item_num, item_desc in IMPORTANT_ITEMS.items():
            if f"item {item_num}" in content_lower:
                detected_items.append(f"Item {item_num} - {item_desc}")
        
        found_keywords = [kw for kw in KEYWORDS if kw in content_lower]
        importance_score = len(detected_items) * 2 + len(found_keywords)
        
        # WyciÄ…gnij fragment dokumentu
        document_excerpt = extract_document_excerpt(content, detected_items)
        
        return {
            'items': detected_items,
            'keywords': found_keywords[:5],
            'importance': importance_score,
            'document_excerpt': document_excerpt,
            'url': f"https://www.sec.gov/cgi-bin/viewer?action=view&cik={cik}&accession_number={accession_number}"
        }
        
    except Exception as e:
        print(f"âš ï¸ Nie moÅ¼na przeanalizowaÄ‡ treÅ›ci {accession_number}: {e}")
        return {
            'items': [], 
            'keywords': [], 
            'importance': 0, 
            'document_excerpt': 'BÅ‚Ä…d pobierania dokumentu',
            'url': filing_url
        }

def analyze_sentiment(analysis: Dict, ticker: str) -> Dict:
    """Analizuje sentyment raportu 8-K"""
    keywords = analysis.get('keywords', [])
    items = analysis.get('items', [])
    
    # Pozytywne sÅ‚owa kluczowe
    bullish_keywords = ['partnership', 'collaboration', 'strategic', 'agreement', 'contract', 
                        'revenue', 'earnings', 'growth', 'expansion', 'joint venture']
    # Negatywne sÅ‚owa kluczowe
    bearish_keywords = ['loss', 'decline', 'lawsuit', 'investigation', 'bankruptcy', 
                        'restructuring', 'termination', 'failure']
    
    bullish_score = sum(1 for kw in keywords if kw in bullish_keywords)
    bearish_score = sum(1 for kw in keywords if kw in bearish_keywords)
    
    # OkreÅ›l sentyment
    if bullish_score > bearish_score:
        sentiment = "ğŸ“ˆ BULLISH"
        color = 5763719  # Zielony
        interpretation = "Pozytywne wiadomoÅ›ci mogÄ… wspieraÄ‡ wzrost ceny. "
        
        if 'partnership' in keywords or 'collaboration' in keywords:
            interpretation += "Nowe partnerstwo moÅ¼e otworzyÄ‡ dodatkowe ÅºrÃ³dÅ‚a przychodÃ³w."
        elif 'acquisition' in keywords or 'merger' in keywords:
            interpretation += "PrzejÄ™cie/fuzja moÅ¼e zwiÄ™kszyÄ‡ wartoÅ›Ä‡ rynkowÄ… spÃ³Å‚ki."
        elif 'revenue' in keywords or 'earnings' in keywords:
            interpretation += "Dobre wyniki finansowe mogÄ… przyciÄ…gnÄ…Ä‡ inwestorÃ³w."
        else:
            interpretation += "Rynek moÅ¼e zareagowaÄ‡ pozytywnie na te wiadomoÅ›ci."
            
    elif bearish_score > bullish_score:
        sentiment = "ğŸ“‰ BEARISH"
        color = 15158332  # Czerwony
        interpretation = "Negatywne wiadomoÅ›ci mogÄ… wywrzeÄ‡ presjÄ™ na cenÄ™ akcji. "
        interpretation += "Zaleca siÄ™ ostroÅ¼noÅ›Ä‡ i monitorowanie sytuacji."
        
    else:
        sentiment = "â¡ï¸ NEUTRALNY"
        color = 15844367  # Å»Ã³Å‚ty
        interpretation = "WiadomoÅ›ci majÄ… mieszany charakter. "
        interpretation += "WpÅ‚yw na cenÄ™ zaleÅ¼eÄ‡ bÄ™dzie od reakcji rynku i dodatkowych szczegÃ³Å‚Ã³w."
    
    return {
        'sentiment': sentiment,
        'color': color,
        'interpretation': interpretation
    }

def send_discord_alert(filing: Dict, analysis: Dict):
    """WysyÅ‚a alert na Discord"""
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ Brak DISCORD_WEBHOOK_URL - pomijam wysyÅ‚anie alertu")
        return
    
    ticker = filing['ticker']
    company = filing['company']
    company_desc = COMPANIES[ticker]['desc']
    date = filing['filingDate']
    
    # Analiza sentymentu
    sentiment_data = analyze_sentiment(analysis, ticker)
    
    # Link do TradingView
    tradingview_link = f"https://www.tradingview.com/chart/?symbol={ticker}"
    
    if analysis['importance'] >= 5:
        priority = "ğŸ”´ BARDZO WAÅ»NE"
    elif analysis['importance'] >= 3:
        priority = "ğŸŸ¡ WAÅ»NE"
    else:
        priority = "ğŸŸ¢ INFORMACYJNE"
    
    # PowiÄ…zane spÃ³Å‚ki z wyjaÅ›nieniami i linkami
    related_companies = RELATIONSHIPS.get(ticker, {})
    if related_companies:
        related_list = []
        count = 0
        for related_ticker, reason in related_companies.items():
            if count >= 4:  # Maksymalnie 4
                break
            tv_link = f"https://www.tradingview.com/chart/?symbol={related_ticker}"
            related_list.append(f"â€¢ [{related_ticker}]({tv_link}) - {reason}")
            count += 1
        related_text = "\n".join(related_list)
    else:
        related_text = "Brak bezpoÅ›rednich powiÄ…zaÅ„ w monitorowanych spÃ³Å‚kach"
    
    items_text = "\n".join([f"â€¢ {item}" for item in analysis['items']]) if analysis['items'] else "Brak wykrytych Items"
    keywords_text = ", ".join(analysis['keywords']) if analysis['keywords'] else "Brak"
    
    embed = {
        "title": f"{priority} - Nowy raport 8-K",
        "description": f"**{company} ({ticker})**\n*{company_desc}*\n\n{sentiment_data['sentiment']}\n*{sentiment_data['interpretation']}*",
        "color": sentiment_data['color'],
        "fields": [
            {"name": "ğŸ“… Data zgÅ‚oszenia", "value": date, "inline": True},
            {"name": "ğŸ“Š Ocena waÅ¼noÅ›ci", "value": f"{analysis['importance']}/10", "inline": True},
            {"name": "ğŸ“‹ Wykryte kategorie", "value": items_text, "inline": False},
            {"name": "ğŸ” Kluczowe sÅ‚owa", "value": keywords_text, "inline": False},
            {"name": "ğŸ”— Potencjalny wpÅ‚yw na", "value": related_text, "inline": False},
            {"name": "ğŸ“ˆ Wykres", "value": f"[OtwÃ³rz na TradingView]({tradingview_link})", "inline": True},
            {"name": "ğŸ“„ Dokument SEC", "value": f"[OtwÃ³rz raport]({analysis['url']})", "inline": True},
            {"name": "ğŸ“„ FRAGMENT DOKUMENTU (tÅ‚umaczenie)", "value": f"```{analysis['document_excerpt']}```", "inline": False}
        ],
        "footer": {"text": f"SEC EDGAR Monitor â€¢ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"}
    }
    
    payload = {"embeds": [embed]}
    
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=10)
        response.raise_for_status()
        print(f"âœ… Alert wysÅ‚any: {ticker} - {date}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d wysyÅ‚ania alertu Discord: {e}")

def check_new_filings():
    """Sprawdza nowe zgÅ‚oszenia dla wszystkich spÃ³Å‚ek"""
    print(f"\nğŸ” Sprawdzam nowe raporty 8-K... [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]")
    
    processed_filings = load_processed_filings()
    new_filings_count = 0
    
    for ticker, info in COMPANIES.items():
        filings = get_recent_filings(info['cik'], ticker)
        
        for filing in filings:
            filing_id = f"{ticker}_{filing['accessionNumber']}"
            
            if filing_id in processed_filings:
                continue
            
            filing_date = datetime.strptime(filing['filingDate'], '%Y-%m-%d')
            if datetime.now() - filing_date > timedelta(hours=48):
                processed_filings.add(filing_id)
                continue
            
            print(f"ğŸ“„ Nowy raport: {ticker} - {filing['filingDate']}")
            
            analysis = analyze_8k_content(filing['accessionNumber'], ticker)
            
            if analysis['items']:
                send_discord_alert(filing, analysis)
                new_filings_count += 1
            
            processed_filings.add(filing_id)
    
    save_processed_filings(processed_filings)
    
    if new_filings_count == 0:
        print("âœ“ Brak nowych raportÃ³w")
    else:
        print(f"âœ“ WysÅ‚ano {new_filings_count} alertÃ³w")

def main():
    """GÅ‚Ã³wna funkcja"""
    print("=" * 60)
    print("ğŸš€ SEC 8-K Monitor - GitHub Actions")
    print("=" * 60)
    print(f"ğŸ“Š Monitorowane spÃ³Å‚ki: {len(COMPANIES)}")
    print(f"ğŸ“‹ Kategorie: {', '.join(IMPORTANT_ITEMS.keys())}")
    print("=" * 60)
    
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ UWAGA: Ustaw DISCORD_WEBHOOK_URL w GitHub Secrets!")
        return
    
    check_new_filings()
    print("\nâœ… ZakoÅ„czono sprawdzanie")

if __name__ == "__main__":
    main()
